{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:41:10.120524Z",
     "start_time": "2024-05-18T14:41:10.101961Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import keys_to_counts, get_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:41:10.167404Z",
     "start_time": "2024-05-18T14:41:10.120524Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = \"D:\\\\studium\\\\analyse\\\\data_prep\\\\src\\\\_2_preproc_pipeline_en\\\\data_preprocessed\\\\2_tokenize_us.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:41:10.183029Z",
     "start_time": "2024-05-18T14:41:10.167404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>text_preproc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US020240139944A1</td>\n",
       "      <td>2024</td>\n",
       "      <td>arm operating system include control device pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US020240139768A1</td>\n",
       "      <td>2024</td>\n",
       "      <td>coating device corresponding coating process d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US020240139853A1</td>\n",
       "      <td>2024</td>\n",
       "      <td>tip separation apparatus welding gun disclose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US020240139933A1</td>\n",
       "      <td>2024</td>\n",
       "      <td>device method controlled motion tool present i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US020240139934A1</td>\n",
       "      <td>2024</td>\n",
       "      <td>teaching method program store medium execute t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  pub_year  \\\n",
       "0  US020240139944A1      2024   \n",
       "1  US020240139768A1      2024   \n",
       "2  US020240139853A1      2024   \n",
       "3  US020240139933A1      2024   \n",
       "4  US020240139934A1      2024   \n",
       "\n",
       "                                       text_preproc2  \n",
       "0  arm operating system include control device pl...  \n",
       "1  coating device corresponding coating process d...  \n",
       "2  tip separation apparatus welding gun disclose ...  \n",
       "3  device method controlled motion tool present i...  \n",
       "4  teaching method program store medium execute t...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:41:10.451987Z",
     "start_time": "2024-05-18T14:41:10.183029Z"
    }
   },
   "outputs": [],
   "source": [
    "# vectorize the text data with tf-idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=20, max_df=0.9)\n",
    "\n",
    "x_vec = vectorizer.fit_transform(df['text_preproc2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:41:10.467612Z",
     "start_time": "2024-05-18T14:41:10.451987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1736"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:41:37.402249Z",
     "start_time": "2024-05-18T14:41:10.467612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LatentDirichletAllocation(learning_method=&#x27;online&#x27;,\n",
       "                                                 learning_offset=50.0,\n",
       "                                                 max_iter=5, random_state=0),\n",
       "             param_grid={&#x27;learning_decay&#x27;: [0.6], &#x27;n_components&#x27;: [8]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LatentDirichletAllocation(learning_method=&#x27;online&#x27;,\n",
       "                                                 learning_offset=50.0,\n",
       "                                                 max_iter=5, random_state=0),\n",
       "             param_grid={&#x27;learning_decay&#x27;: [0.6], &#x27;n_components&#x27;: [8]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, learning_offset=50.0,\n",
       "                          max_iter=5, random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, learning_offset=50.0,\n",
       "                          max_iter=5, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(learning_method='online',\n",
       "                                                 learning_offset=50.0,\n",
       "                                                 max_iter=5, random_state=0),\n",
       "             param_grid={'learning_decay': [0.6], 'n_components': [8]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Search Param\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "search_params = {\n",
    "    'n_components': [n_topics],\n",
    "    'learning_decay': [0.6]\n",
    "}\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation(max_iter=5, learning_method='online', learning_offset=50., random_state=0)\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "# Do the Grid Search\n",
    "model.fit(x_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:41:38.240854Z",
     "start_time": "2024-05-18T14:41:37.402249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.6, 'n_components': 8}\n",
      "Best Log Likelihood Score:  -692924.5308594698\n",
      "Model Perplexity:  465.4696900440025\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(x_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1\n",
    "```\n",
    "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 4}\n",
    "Best Log Likelihood Score:  -744378.7146935398\n",
    "Model Perplexity:  579.4436712246056\n",
    "```\n",
    "#### 2\n",
    "```\n",
    "Best Model's Params:  {'learning_decay': 0.6, 'n_components': 8}\n",
    "Best Log Likelihood Score:  -692924.5308594698\n",
    "Model Perplexity:  465.4696900440025\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=20, max_df=0.9)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:41:38.931667Z",
     "start_time": "2024-05-18T14:41:38.240854Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_output = best_lda_model.transform(x_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "us_outpath = Path(\"../output/us\")\n",
    "model_outpath = us_outpath / \"lda_model.pkl\"\n",
    "ldaout_outpath = us_outpath / \"lda_output.pkl\"\n",
    "vec_outpath = us_outpath / \"vectorizer.pkl\"\n",
    "# Save the LDA model\n",
    "joblib.dump(best_lda_model, model_outpath) \n",
    "joblib.dump(vectorizer, vec_outpath)\n",
    "joblib.dump(lda_output, ldaout_outpath); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:41:40.857948Z",
     "start_time": "2024-05-18T14:41:39.014617Z"
    }
   },
   "outputs": [],
   "source": [
    "#this is by far the easiest way to load a pre-trained sklearn lda model onto pyLDAvis\n",
    "#there are other means of using this visible on pyLDAvis' main repo\n",
    "\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.sklearn\n",
    "# pyLDAvis.enable_notebook()\n",
    "\n",
    "# feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# vectorizer.get_feature_names = lambda: feature_names\n",
    "\n",
    "# display_data = pyLDAvis.sklearn.prepare(best_lda_model, #our pre-trained LDA model\n",
    "#                          x_vec, #this gives us our document-term matrix\n",
    "#                         vectorizer) #the vectoriser object\n",
    "                        \n",
    "# pyLDAvis.display(display_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "orig_data_path = \"D:\\\\studium\\\\analyse\\\\data_prep\\\\src\\\\_2_preproc_pipeline_en\\\\data_preprocessed\\\\1_txt_cleaning_us.csv\"\n",
    "df_most_representative_docs = m_utils.get_most_reprdocs(df['id'], lda_output, orig_data_path, best_lda_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_reprdoc_outpath = \"../output/us/most_repr_docsptopic.csv\"\n",
    "df_most_representative_docs.to_csv(most_reprdoc_outpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_angew_programm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
