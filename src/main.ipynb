{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 157789 entries, 0 to 157788\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      157789 non-null  object\n",
      " 1   text    157789 non-null  object\n",
      " 2   label   157789 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# read csv with pandas\n",
    "import pandas as pd\n",
    "\n",
    "data_path = '../data_input/train.csv'\n",
    "df = pd.read_csv(data_path, usecols=['id', 'text', 'label'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    vocab_size: int\n",
    "    n_embd: int\n",
    "    n_hidden: int\n",
    "    batch_size: int\n",
    "    context_length: int\n",
    "    n_workers: int\n",
    "    # /path/to/save/checkpoints\n",
    "    ckpt_path = None\n",
    "    dropout = 0.1\n",
    "    checkpoint_dir: Path = Path(\"../output/checkpoints/\").absolute()\n",
    "\n",
    "\n",
    "def get_default_config() -> Config:\n",
    "    cfg =  Config(\n",
    "        n_workers=1,\n",
    "        vocab_size=5001,\n",
    "        n_embd=16,\n",
    "        n_hidden=64,\n",
    "        batch_size=32,\n",
    "        context_length=32,\n",
    "    )\n",
    "\n",
    "    # Get the latest checkpoint file path\n",
    "    latest_ckpt_file = sorted(cfg.checkpoint_dir.glob('*.ckpt'), key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "    cfg.ckpt_path = None if latest_ckpt_file == [] else latest_ckpt_file[0]\n",
    "    return cfg\n",
    "\n",
    "cfg = get_default_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(cfg.n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(cfg.n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(cfg.n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(cfg.context_length, cfg.context_length)))\n",
    "\n",
    "        self.dropout = nn.Dropout(cfg.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(cfg.n_embd, cfg.n_embd)\n",
    "        self.dropout = nn.Dropout(cfg.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class TransfEncModel(L.LightningModule):\n",
    "    def __init__(self, cfg: Config, n_classes=5):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(cfg.vocab_size, cfg.n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(cfg.context_length, cfg.n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(cfg.n_embd, n_head=1) for _ in range(1)])\n",
    "        self.ln_f = nn.LayerNorm(cfg.n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(cfg.context_length * cfg.n_embd, n_classes)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=self.device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T*C)  # (B,T,C) -> (B, T*C)\n",
    "        logits = self.lm_head(x) # (B,n_classes)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, target = batch\n",
    "        output = self(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(output, target.view(-1))\n",
    "        # lossi.append(loss.log10().item())\n",
    "        # with torch.no_grad():\n",
    "        # lr = optimizer.param_groups[0]['lr']\n",
    "        # ud.append([((lr*p.grad).std() / p.output.std()).log10().item() for p in model.parameters()])\n",
    "        # logs metrics for each training_step,\n",
    "        # and the average across the epoch, to the progress bar and logger\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_epoch=True, prog_bar=True, logger=True, sync_dist=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, target = batch\n",
    "        output = self(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(output, target.view(-1))\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True,prog_bar=True, sync_dist=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 5001\n"
     ]
    }
   ],
   "source": [
    "# split X and Y into train and val, stratify by Y\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "\n",
    "from script.data import get_train_test_split\n",
    "\n",
    "Xtr, Xval, Ytr, Yval = get_train_test_split(\n",
    "    df[\"text\"], df[\"label\"], context_length=cfg.context_length, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([126231, 32]), torch.Size([31558, 32]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape, Xval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86357"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransfEncModel(cfg)\n",
    "sum([p.nelement() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = list(model.modules())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the forward hook function\n",
    "def forward_hook(module, input, output):\n",
    "    module.out = output  # Store output in the module itself\n",
    "    # module.out.retain_grad()  # Tell PyTorch to keep the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(5001, 16)\n",
      "Embedding(32, 16)\n",
      "Sequential(\n",
      "  (0): Block(\n",
      "    (sa): MultiHeadAttention(\n",
      "      (heads): ModuleList(\n",
      "        (0): Head(\n",
      "          (key): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (query): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (value): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (proj): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ffwd): FeedFoward(\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=64, out_features=16, bias=True)\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ln1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    (ln2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Block(\n",
      "  (sa): MultiHeadAttention(\n",
      "    (heads): ModuleList(\n",
      "      (0): Head(\n",
      "        (key): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (query): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (value): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (proj): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ffwd): FeedFoward(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=16, bias=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ln1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "  (ln2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "MultiHeadAttention(\n",
      "  (heads): ModuleList(\n",
      "    (0): Head(\n",
      "      (key): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (query): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (value): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Head(\n",
      "    (key): Linear(in_features=16, out_features=16, bias=False)\n",
      "    (query): Linear(in_features=16, out_features=16, bias=False)\n",
      "    (value): Linear(in_features=16, out_features=16, bias=False)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "Head(\n",
      "  (key): Linear(in_features=16, out_features=16, bias=False)\n",
      "  (query): Linear(in_features=16, out_features=16, bias=False)\n",
      "  (value): Linear(in_features=16, out_features=16, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=16, out_features=16, bias=False)\n",
      "Linear(in_features=16, out_features=16, bias=False)\n",
      "Linear(in_features=16, out_features=16, bias=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Linear(in_features=16, out_features=16, bias=True)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "FeedFoward(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Linear(in_features=16, out_features=64, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=64, out_features=16, bias=True)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n"
     ]
    }
   ],
   "source": [
    "# loop over model layers except the last one\n",
    "for layer in layers[:-1]:\n",
    "  layer.register_forward_hook(forward_hook)\n",
    "  print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with pytorch lightning\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(Xtr, Ytr)\n",
    "val_dataset = TensorDataset(Xval, Yval)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=cfg.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                     | Type       | Params\n",
      "--------------------------------------------------------\n",
      "0 | token_embedding_table    | Embedding  | 80.0 K\n",
      "1 | position_embedding_table | Embedding  | 512   \n",
      "2 | blocks                   | Sequential | 3.2 K \n",
      "3 | ln_f                     | LayerNorm  | 32    \n",
      "4 | lm_head                  | Linear     | 2.6 K \n",
      "--------------------------------------------------------\n",
      "86.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "86.4 K    Total params\n",
      "0.345     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78093926e6441e1ae3d637fb5e307de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paul-\\anaconda3\\envs\\ml_angew_programm\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\paul-\\anaconda3\\envs\\ml_angew_programm\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1c7ff5c872426c82e2e2665d6c161a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a761bc833f49cbb621da183f1db27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2078333d214021bb317b3f8b098fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=2, accelerator='cpu')\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'activation distribution')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i, layer in enumerate(layers[:-1]): # note: exclude the output layer\n",
    "  if isinstance(layer, nn.Tanh):\n",
    "    t = layer.out\n",
    "    print('layer %d (%s): mean %+.2f, std %.2f, saturated: %.2f%%' % (i, layer.__class__.__name__, t.mean(), t.std(), (t.abs() > 0.97).float().mean()*100))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'layer {i} ({layer.__class__.__name__})')\n",
    "plt.legend(legends);\n",
    "plt.title('activation distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'gradient distribution')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i, layer in enumerate(layers[:-1]): # note: exclude the output layer\n",
    "  if isinstance(layer, nn.Tanh):\n",
    "    t = layer.out.grad\n",
    "    print('layer %d (%10s): mean %+f, std %e' % (i, layer.__class__.__name__, t.mean(), t.std()))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'layer {i} ({layer.__class__.__name__}')\n",
    "plt.legend(legends);\n",
    "plt.title('gradient distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m t \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m----> 7\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight \u001b[39m\u001b[38;5;132;01m%10s\u001b[39;00m\u001b[38;5;124m | mean \u001b[39m\u001b[38;5;132;01m%+f\u001b[39;00m\u001b[38;5;124m | std \u001b[39m\u001b[38;5;132;01m%e\u001b[39;00m\u001b[38;5;124m | grad:data ratio \u001b[39m\u001b[38;5;132;01m%e\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtuple\u001b[39m(p\u001b[38;5;241m.\u001b[39mshape), \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m(), t\u001b[38;5;241m.\u001b[39mstd(), t\u001b[38;5;241m.\u001b[39mstd() \u001b[38;5;241m/\u001b[39m p\u001b[38;5;241m.\u001b[39mstd()))\n\u001b[0;32m      8\u001b[0m   hy, hx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhistogram(t, density\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m   plt\u001b[38;5;241m.\u001b[39mplot(hx[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach(), hy\u001b[38;5;241m.\u001b[39mdetach())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'mean'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i,p in enumerate(model.parameters()):\n",
    "  t = p.grad\n",
    "  if p.ndim == 2:\n",
    "    print('weight %10s | mean %+f | std %e | grad:data ratio %e' % (tuple(p.shape), t.mean(), t.std(), t.std() / p.std()))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'{i} {tuple(p.shape)}')\n",
    "plt.legend(legends)\n",
    "plt.title('weights gradient distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters()):\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot([ud[j][i] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mud\u001b[49m))])\n\u001b[0;32m      6\u001b[0m     legends\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m i)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ud)], [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# these ratios should be ~1e-3, indicate on plot\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ud' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "for i,p in enumerate(model.parameters()):\n",
    "  if p.ndim == 2:\n",
    "    plt.plot([ud[j][i] for j in range(len(ud))])\n",
    "    legends.append('param %d' % i)\n",
    "plt.plot([0, len(ud)], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "plt.legend(legends);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.0960\n"
     ]
    }
   ],
   "source": [
    "# with torch.no_grad():\n",
    "    # train validation loss\n",
    "# outputs1 = model(Xtr)\n",
    "# loss = F.cross_entropy(outputs1, Ytr)\n",
    "# print(f'Training loss: {loss.item():.4f}')\n",
    "\n",
    "outputs = model(Xval)\n",
    "loss = torch.functional.F.cross_entropy(outputs, Yval)\n",
    "print(f'Validation loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor(1.1228, grad_fn=<NllLossBackward0>)  \n",
    "tensor(1.0828, grad_fn=<NllLossBackward0>)  \n",
    "tensor(1.0767, grad_fn=<NllLossBackward0>) on mlpc  \n",
    "Validation loss: 1.0657 on wavenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64      6353\n",
      "           1       0.43      0.36      0.39      6462\n",
      "           2       0.40      0.35      0.38      6337\n",
      "           3       0.46      0.50      0.48      6244\n",
      "           4       0.63      0.75      0.68      6162\n",
      "\n",
      "    accuracy                           0.52     31558\n",
      "   macro avg       0.51      0.52      0.51     31558\n",
      "weighted avg       0.51      0.52      0.51     31558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "Y_pred = outputs.argmax(dim=1).detach().numpy()\n",
    "Y_true = Yval.numpy()\n",
    "\n",
    "print(classification_report(Y_true, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_angew_programm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
